# ğŸ”¤ NMT-ENG-BODO â€” Neural Machine Translation for English â†”ï¸ Bodo

> ğŸ§  A transformer-based NMT system to bridge the language gap for the low-resource Bodo language using state-of-the-art deep learning techniques.

---

## ğŸŒ Project Overview

This project presents a **Neural Machine Translation (NMT)** system developed using **transformer architecture** to translate between **English** and **Bodo** â€” an indigenous, low-resource language of Northeast India. Built as part of my research into low-resource NLP, this project leverages **attention-based models** and parallel corpora to demonstrate scalable translation capabilities.

---

## ğŸš€ Highlights

- âœ… **Transformer-based encoder-decoder architecture**
- ğŸŒ **Low-resource language support** (Bodo)
- ğŸ“ Parallel corpus files: `s.csv`, `sd.csv`
- ğŸ““ Interactive Jupyter Notebook: `sd.ipynb` for training & evaluation
- ğŸ”¤ Integrated subword tokenization with `SentencePiece`
- ğŸ“Š Evaluation metrics: BLEU, METEOR, ROUGE, TER, sacreBLEU

---

## ğŸ“ Repository Structure


---

## ğŸ› ï¸ Tech Stack

| Category     | Tools Used                          |
|--------------|-------------------------------------|
| ğŸ‘©â€ğŸ’» Language   | Python 3.x                           |
| ğŸ“š Libraries  | pandas, NumPy, SentencePiece, matplotlib |
| ğŸ§  Frameworks | TensorFlow, Keras (Transformer APIs)  |
| ğŸ“„ Data Format | CSV parallel corpora                |

---

## ğŸ““ Model Workflow (via `sd.ipynb`)

1. **Data Preprocessing**  
   - Load `s.csv` and `sd.csv`  
   - Normalize & clean parallel sentences  
   - Tokenize using `SentencePiece` subword units

2. **Transformer Model Definition**  
   - Encoder-decoder with multi-head attention  
   - Positional encoding, dropout, masking

3. **Training & Evaluation**  
   - Sprase Categorical cross-entropy loss
   - ADAM Optimizer.
   - Accuracy tracking + BLEU score (if configured)  
   - Training/validation loss visualization


---

## ğŸ§ª Sample Translation Example

```python
Input: "The school is closed today."
Output (Bodo): "Skulwi dong bathw swrjao."
````

## ğŸŒ± Why This Project Matters
Bodo is among the many underrepresented languages in NLP.
This project contributes toward:

ğŸ§‘â€ğŸ« Democratizing AI for marginalized language speakers

ğŸŒ Building inclusive translation systems

ğŸ”¬ Advancing research on low-resource language modeling

##ğŸ“œ License
MIT License Â© [Your Name or GitHub Handle]

Feel free to fork, modify, and contribute!
For academic or research use, attribution is appreciated.


